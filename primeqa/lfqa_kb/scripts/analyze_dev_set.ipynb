{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze specific examples (e.g. 5) for our different kg setups\n",
    "# look at all and subset that likely to need kg (avg rouge)\n",
    "# output subset scores at different thresholds\n",
    "import json\n",
    "\n",
    "# experiment_dir = \"/dccstor/srosent2/primeqa-mengxia/experiments/oracle-kg/analyze/\"\n",
    "#experiments = [\"/default/\",\"all/kg_vocab/\", \"all/kg_triples\", \"all/kg_sentences\", \"all/kg_sentences-train_more_eps3/dev\"]\n",
    "# experiments = [\"all/kg_sentences-train_more_eps3/5ktrain/\"]\n",
    "\n",
    "# experiment_dir = \"/dccstor/srosent2/primeqa-mengxia/experiments/filter_pr/\"\n",
    "# experiments = [\"/dccstor/srosent2/primeqa-mengxia/experiments/oracle-kg/analyze/default/\", experiment_dir + \"all/kg_vocab_score_cased\", experiment_dir + \"all/kg_triple_score_cased\", \n",
    "# experiment_dir + \"best/kg_vocab_score_cased\", experiment_dir + \"best/kg_triple_score_cased\"]\n",
    "\n",
    "\n",
    "experiment_dir = \"/dccstor/srosent2/primeqa-mengxia/experiments/filter_pr/\"\n",
    "experiments = [\"/dccstor/srosent2/primeqa-mengxia/experiments/asqa/default-cased/\"]\n",
    "\n",
    "prediction_file = \"/output/eval_predictions.json\"\n",
    "reference_file = \"/output/eval_references.json\"\n",
    "\n",
    "threshold_file = \"/dccstor/srosent2/primeqa-mengxia/experiments/oracle-kg/analyze/dev_id2score.json\"\n",
    "threshold_file = \"/dccstor/srosent2/primeqa-mengxia/data/asqa/passages_kg_pr/dev_id2score.json\"\n",
    "\n",
    "dev_file = \"/dccstor/srosent2/primeqa-mengxia/data/dpr-100passages_withkg_best_all/eli5-dev-kilt-dpr-kg-00.json\"\n",
    "# dev_file = \"/dccstor/srosent2/primeqa-mengxia/data/dpr-100passages_withkg_best_all/eli5-train-kilt-dpr-kg-00.json\"\n",
    "\n",
    "def load_json(file_name):\n",
    "    print(file_name)\n",
    "    with open (file_name, 'r') as f:\n",
    "        data_lines = json.load(f)\n",
    "            \n",
    "    return data_lines\n",
    "\n",
    "def load_jsonl(file_name):\n",
    "    print(file_name)\n",
    "    json_lines = []\n",
    "    with open (file_name, 'r') as f:\n",
    "        data_lines = f.readlines()\n",
    "        for line in data_lines:\n",
    "           json_lines.append(json.loads(line))\n",
    "    return json_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dccstor/srosent2/primeqa-mengxia/experiments/asqa/default-cased//output/eval_predictions.json\n",
      "/dccstor/srosent2/primeqa-mengxia/experiments/asqa/default-cased//output/eval_references.json\n",
      "/dccstor/srosent2/primeqa-mengxia/data/dpr-100passages_withkg_best_all/eli5-dev-kilt-dpr-kg-00.json\n"
     ]
    }
   ],
   "source": [
    "all_prediction_data = {}\n",
    "\n",
    "for experiment in experiments:\n",
    "    all_prediction_data[experiment] = load_json(experiment + prediction_file)\n",
    "\n",
    "with open (threshold_file, 'r') as f:\n",
    "    threshold_data = json.load(f)\n",
    "reference_data = load_json(experiments[0] + reference_file)\n",
    "\n",
    "dev_data = load_jsonl(dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_scores(data, thresholds, threshold=0):\n",
    "    rouge_scores = {}\n",
    "    for experiment in data:\n",
    "        rougeL = 0\n",
    "        num_instances = 0\n",
    "        for instance in data[experiment]:\n",
    "            if thresholds[instance['id']][1] >= threshold:\n",
    "                rougeL += instance['rougeL']\n",
    "                num_instances += 1\n",
    "        if num_instances == 0:\n",
    "            rouge_scores[experiment] = 0\n",
    "        else:\n",
    "            rouge_scores[experiment] = rougeL / num_instances\n",
    "    return rouge_scores, num_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold, num instances, /,\n",
      "0.0,948,0.4043821532860462,\n",
      "0.1,511,0.3576703141808277,\n",
      "0.2,195,0.32954506918081733,\n",
      "0.30000000000000004,36,0.3188683163907594,\n",
      "0.4,5,0.23831348530076615,\n",
      "0.5,2,0.23072186709861459,\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     rouge_scores, num_instances \u001b[39m=\u001b[39m compute_scores(all_prediction_data, threshold_data, i\u001b[39m*\u001b[39;49m\u001b[39m.1\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mcompute_scores\u001b[0;34m(data, thresholds, threshold)\u001b[0m\n\u001b[1;32m      8\u001b[0m             rougeL \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m instance[\u001b[39m'\u001b[39m\u001b[39mrougeL\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m             num_instances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     rouge_scores[experiment] \u001b[39m=\u001b[39m rougeL \u001b[39m/\u001b[39;49m num_instances\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m rouge_scores, num_instances\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0,10):\n",
    "   \n",
    "    rouge_scores, num_instances = compute_scores(all_prediction_data, threshold_data, i*.1)\n",
    "\n",
    "    scores = \"\"\n",
    "    if i == 0:\n",
    "        scores += \"threshold, num instances, \"\n",
    "        for score in rouge_scores:\n",
    "            scores += str(score[score.rindex(\"/\"):]) + \",\"\n",
    "        scores += \"\\n\"    \n",
    "    scores += str(i*.1) + \",\" + str(num_instances) + \",\"\n",
    "    for score in rouge_scores:\n",
    "        scores += str(rouge_scores[score]) + \",\"\n",
    "    print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_answer(answers, filter=\"rouge\"):\n",
    "    best_answer = None\n",
    "    best_score = 0\n",
    "\n",
    "    for answer in answers:\n",
    "        if filter == \"rouge\":\n",
    "            if answer['meta']['rouge'] > best_score:\n",
    "                best_score = answer['meta']['rouge']\n",
    "                best_answer = answer\n",
    "        elif filter == \"size_kg\":\n",
    "            if len(answer['kg_vocab']) > best_score:\n",
    "                best_score = len(answer['kg_vocab'])\n",
    "                best_answer = answer\n",
    "    return best_answer\n",
    "\n",
    "def get_best_kg_data(instances, text_column='sentence', threshold=2):\n",
    "    output = \"\"\n",
    "    for instance in instances:\n",
    "        if instance['count'] >= threshold:\n",
    "            output += instance[text_column] + \" (\" + str(instance['count']) + \")\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1oy5tc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m output\u001b[39m.\u001b[39mappend(instance[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m output\u001b[39m.\u001b[39mappend(dev_data[index][\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m output\u001b[39m.\u001b[39mappend(threshold_data[instance[\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     16\u001b[0m answers \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m answer \u001b[39min\u001b[39;00m instance[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;31mKeyError\u001b[0m: '1oy5tc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# keep 5-10 examples to analyze the output from each system.\n",
    "count = 0\n",
    "index = 0\n",
    "all_output = []\n",
    "for instance in reference_data:\n",
    "    output = []\n",
    "    # if threshold_data[instance['id']] < 0.4:\n",
    "    #     index+=1\n",
    "    #     continue\n",
    "    # if count < 15:\n",
    "    output.append(instance['id'])\n",
    "    output.append(dev_data[index]['input'])\n",
    "    #output.append(threshold_data[instance['id']])\n",
    "    answers = \"\"\n",
    "\n",
    "    for answer in instance['answers']:\n",
    "        answers += \"ANSWER: \" + answer + \"\\n\"\n",
    "    output.append(answers)\n",
    "\n",
    "    answer = get_best_answer(dev_data[index][\"output\"], filter='size_kg')\n",
    "\n",
    "    output.append(answer['answer'])\n",
    "    # output.append(answer['meta']['rouge']/len(answers))\n",
    "    output.append(answer['kg_vocab'])\n",
    "    output.append(get_best_kg_data(answer['kg_triples'], text_column='text'))\n",
    "    output.append(get_best_kg_data(answer['kg_sentences']))\n",
    "\n",
    "    for experiment in all_prediction_data:\n",
    "        \n",
    "        pred_instance = all_prediction_data[experiment][index]\n",
    "\n",
    "        output.append(pred_instance['prediction_text'])\n",
    "        output.append(pred_instance['rougeL'])\n",
    "        count += 1\n",
    "    all_output.append(output)\n",
    "    # if count >= 15:\n",
    "    #     break\n",
    "    index+=1\n",
    "with pd.ExcelWriter(experiment_dir + \"/analysis-dev-filtering.xlsx\", engine='xlsxwriter', options={'strings_to_formulas':False}) as writer:\n",
    "        df = pd.DataFrame(all_output)\n",
    "        df.to_excel(writer, sheet_name='Sheet1') #columns=[\"id\",\"question\",\"answers\",\"default\",\"RougeL\",\"kg vocab\",\"RougeL\",\"kg triples\",\"Rouge L\",\"kg sentences\",\"Rouge L\"])\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "        cell_format = workbook.add_format({'text_wrap': True})\n",
    "        worksheet.set_column('A:Z', cell_format=cell_format)\n",
    "print(len(all_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primeqa4.24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d32919132f66e210a1b695050b8f424e37551142a4189348e2af6a594afe21a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
