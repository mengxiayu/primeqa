{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Token\n",
    "stop_words_getter = lambda token: token.is_stop or token.lower_ in STOP_WORDS \\\n",
    "                                                or token.lemma_ in STOP_WORDS\n",
    "Token.set_extension('is_stop', getter=stop_words_getter, force=True)\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"parser\",\"ner\"])\n",
    "def get_nonstop_words(x):\n",
    "    y = [\n",
    "        token.lemma_ for token in nlp(x) if\n",
    "        not token.is_stop\n",
    "        and not token.is_currency\n",
    "        and not token.is_digit\n",
    "        and not token.is_punct\n",
    "        and not token.is_space\n",
    "        and not token.like_num\n",
    "        and not token.pos_ == \"PROPN\"\n",
    "    ]\n",
    "    return set(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 20 passages & Best Answer on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-dpr.json\"\n",
    "data_lines = []\n",
    "with open (data_file, 'r') as f:\n",
    "    for line in f:\n",
    "        data_lines.append(json.loads(line.strip()))\n",
    "\n",
    "text_passages = []\n",
    "text_answers = []\n",
    "for data in data_lines:\n",
    "    passages = [x[\"text\"] for x in data[\"passages\"]]\n",
    "    answers =[x[\"answer\"] for x in data[\"output\"] if \"answer\" in x]\n",
    "    text_passages.append(passages)\n",
    "    text_answers.append(answers)\n",
    "\n",
    "import pickle\n",
    "all_passages = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_psg.pkl\", 'rb'))\n",
    "all_answers = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_ans.pkl\", 'rb'))\n",
    "\n",
    "max_overlaps = []\n",
    "for idx in range(len(all_passages)):\n",
    "    max_overlap = [0, 0, \"\"]\n",
    "    psg = set().union(*all_passages[idx])\n",
    "    # for i, psg in enumerate(all_passages[idx]):\n",
    "    for j, ans in enumerate(all_answers[idx]):\n",
    "        overlap = len(psg & ans)\n",
    "        if overlap > max_overlap[0]:\n",
    "            max_overlap = [overlap, overlap/len(ans), j]\n",
    "    print(f\"#overlap: {max_overlap[0]}; #overlap ratio: {max_overlap[1]:.2f}\\n- Answer: {text_answers[idx][max_overlap[2]]}\")\n",
    "    print('------')\n",
    "    max_overlaps.append(max_overlap)\n",
    "\n",
    "print(\"average #overlap\", sum([x[0] for x in max_overlaps])/len(max_overlaps))\n",
    "print(\"average (#overlap/#gold_answer) of best passage & best answer overlap:\", sum([x[1] for x in max_overlaps])/len(max_overlaps))\n",
    "from collections import Counter\n",
    "cnt = Counter([x[0] for x in max_overlaps])\n",
    "print(\"#overlap freq\")\n",
    "for overlap, freq in sorted(cnt.items()):\n",
    "    print(overlap, freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct train dataset for passage-answer overlap\n",
    "# passage: top n passages\n",
    "# answer: all answers that score >= 30\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "all_answers = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_ans_train.pkl\", 'rb'))\n",
    "all_passages = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_psg_train.pkl\", \"rb\"))\n",
    "\n",
    "data_file = f\"/dccstor/myu/data/kilt_eli5_dpr/eli5-train-kilt-dpr.json\"\n",
    "\n",
    "with open (data_file, 'r') as f:\n",
    "    data_lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "assert len(all_answers) == len(all_passages) == len(data_lines)\n",
    "\n",
    "overlaps = []\n",
    "fw = open(f\"/dccstor/myu/data/kilt_eli5_dpr/eli5-train-kilt-oraclekg.json\", 'w')\n",
    "for idx, data in enumerate(data_lines):\n",
    "    answers_data = [x for x in data[\"output\"] if \"answer\" in x and x[\"meta\"][\"score\"] >= 3]\n",
    "    kg_data = []\n",
    "    assert len(answers_data) == len(all_answers[idx])\n",
    "    words_psg = all_passages[idx]\n",
    "    \n",
    "    for i, words_ans in enumerate(all_answers[idx]):\n",
    "        word_overlap = words_psg & words_ans\n",
    "        kg_data.append(list(word_overlap))  \n",
    "        overlaps.append([len(word_overlap), len(word_overlap)/len(words_ans) if len(words_ans)>0 else 0, len(word_overlap)/len(words_psg)])\n",
    "    data[\"output\"] = answers_data\n",
    "    # assert len(data[\"output\"]) > 0\n",
    "    data[\"kg_vocab\"] = kg_data\n",
    "    fw.write(json.dumps(data)+'\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(overlaps))\n",
    "print(sum([x[0] for x in overlaps])/len(overlaps), \n",
    "    sum([x[1] for x in overlaps])/len(overlaps),\n",
    "    sum([x[2] for x in overlaps])/len(overlaps))\n",
    "from collections import Counter\n",
    "cnt = Counter([x[0] for x in overlaps])\n",
    "for k,v in sorted(cnt.items()):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/dccstor/myu/data/kilt_eli5/eli5-train-kilt.json\") as f:\n",
    "    data = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis on train dataset for passage-answer overlap\n",
    "# 20 passages; best answer\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "all_answers = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_ans_train.pkl\", 'rb'))\n",
    "all_passages = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_psg_train.pkl\", \"rb\"))\n",
    "\n",
    "data_file = f\"/dccstor/myu/data/kilt_eli5_dpr/eli5-train-kilt-dpr.json\"\n",
    "\n",
    "with open (data_file, 'r') as f:\n",
    "    data_lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "assert len(all_answers) == len(all_passages) == len(data_lines)\n",
    "\n",
    "overlaps = []\n",
    "# fw = open(f\"/dccstor/myu/data/kilt_eli5_dpr/eli5-train-kilt-oraclekg-single.json\", 'w')\n",
    "for idx, data in enumerate(data_lines):\n",
    "    answers_data = [x for x in data[\"output\"] if \"answer\" in x and x[\"meta\"][\"score\"] >= 3]\n",
    "    \n",
    "    assert len(answers_data) == len(all_answers[idx])\n",
    "    kg_data = []\n",
    "    words_psg = all_passages[idx][:n]\n",
    "    max_recall = 0.0\n",
    "    best_answer = None\n",
    "    best_overlap = [0,0,0]\n",
    "    for i, words_ans in enumerate(all_answers[idx]):\n",
    "        words_psg = set().union(*words_psg)\n",
    "        word_overlap = words_psg & words_ans\n",
    "        if len(words_ans) == 0:\n",
    "            print(answers_data[i][\"answer\"])\n",
    "        recall = len(word_overlap)/len(words_ans) if len(words_ans) > 0 else 0\n",
    "        if recall >= max_recall:\n",
    "            max_recall = recall\n",
    "            best_answer = answers_data[i]\n",
    "            kg_data = list(word_overlap)\n",
    "            best_overlap = [len(word_overlap), recall, len(word_overlap)/len(words_psg)]\n",
    "\n",
    "    # assert best_answer is not None\n",
    "    overlaps.append(best_overlap)\n",
    "    # data[\"output\"] = [best_answer]\n",
    "    # data[\"kg_vocab\"] = [kg_data]\n",
    "    # fw.write(json.dumps(data)+'\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(overlaps))\n",
    "print(sum([x[0] for x in overlaps])/len(overlaps), \n",
    "    sum([x[1] for x in overlaps])/len(overlaps)*100,\n",
    "    sum([x[2] for x in overlaps])/len(overlaps)*100)\n",
    "from collections import Counter\n",
    "cnt = Counter([x[0] for x in overlaps])\n",
    "for k,v in sorted(cnt.items()):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct dev dataset for passage-answer overlap\n",
    "# top n passages; best answer\n",
    "import json\n",
    "import pickle\n",
    "all_answers = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_ans.pkl\", 'rb'))\n",
    "all_passages = pickle.load(open(\"/dccstor/myu/experiments/eli5_analysis/all_psg_dev.pkl\", \"rb\"))\n",
    "\n",
    "data_file = f\"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-dpr.json\"\n",
    "\n",
    "with open (data_file, 'r') as f:\n",
    "    data_lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "assert len(all_answers) == len(all_passages) == len(data_lines)\n",
    "overlaps = []\n",
    "fw = open(f\"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-oraclekg.json\", 'w')\n",
    "for idx, data in enumerate(data_lines):\n",
    "    answers_data = [x for x in data[\"output\"] if \"answer\" in x]\n",
    "    \n",
    "    assert len(answers_data) == len(all_answers[idx])\n",
    "    kg_data = []\n",
    "    words_psg = all_passages[idx]\n",
    "    max_recall = 0.0\n",
    "    best_answer = None\n",
    "    best_overlap = [0,0,0]\n",
    "    for i, words_ans in enumerate(all_answers[idx]):\n",
    "        # words_psg = set().union(*words_psg)\n",
    "        word_overlap = words_psg & words_ans\n",
    "        if len(words_ans) == 0:\n",
    "            # print(answers_data[i][\"answer\"])\n",
    "            continue\n",
    "        recall = len(word_overlap)/len(words_ans)\n",
    "        if recall >= max_recall:\n",
    "            max_recall = recall\n",
    "            best_answer = answers_data[i]\n",
    "            kg_data = list(word_overlap)\n",
    "            best_overlap = [len(word_overlap), len(word_overlap)/len(words_ans), len(word_overlap)/len(words_psg)]\n",
    "    assert best_answer is not None\n",
    "    overlaps.append(best_overlap)\n",
    "    data[\"output\"] = [best_answer]\n",
    "    data[\"kg_vocab\"] = [kg_data]\n",
    "    fw.write(json.dumps(data)+'\\n')   \n",
    "print(len(overlaps))\n",
    "print(sum([x[0] for x in overlaps])/len(overlaps), \n",
    "    sum([x[1] for x in overlaps])/len(overlaps)*100,\n",
    "    sum([x[2] for x in overlaps])/len(overlaps)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_overlaps = overlap_kg_ans(\"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-dpr-kg-hop3.json\", \"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-dpr.json\")\n",
    "print(\"average #overlap\", sum([x[0] for x in max_overlaps])/len(max_overlaps))\n",
    "print(\"average (#overlap/#gold_answer) of 3-hop kg & best answer overlap:\", sum([x[1] for x in max_overlaps])/len(max_overlaps))\n",
    "print(\"average (#overlap/#kg) of 3-hop kg & best answer overlap:\", sum([x[2] for x in max_overlaps])/len(max_overlaps))\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter([x[0] for x in max_overlaps])\n",
    "print(\"#overlap freq\")\n",
    "for overlap, freq in sorted(cnt.items()):\n",
    "    print(overlap, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_overlaps = overlap_kg_ans(\"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-dpr-kg-hop3.json\", \"/dccstor/myu/data/kilt_eli5_dpr/eli5-dev-kilt-dpr.json\")\n",
    "print(\"average #overlap\", sum([x[0] for x in max_overlaps])/len(max_overlaps))\n",
    "print(\"average (#overlap/#gold_answer) of 3-hop kg & best answer overlap:\", sum([x[1] for x in max_overlaps])/len(max_overlaps))\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter([x[0] for x in max_overlaps])\n",
    "print(\"#overlap freq\")\n",
    "for overlap, freq in sorted(cnt.items()):\n",
    "    print(overlap, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "with open(\"/dccstor/myu/experiments/eli5_fid_greedy_ctx3_0729/eval_predictions.json\", 'r') as f:\n",
    "    preds = [get_nonstop_words(x[\"prediction_text\"]) for x in json.load(f)]\n",
    "    # pickle.dump(preds, open(\"/dccstor/myu/experiments/eli5_fid_greedy_ctx3_0729/eval_pred_nonstop.pkl\", 'wb'))\n",
    "with open(\"/dccstor/myu/experiments/eli5_fid_kghop2_greedy_ctx3_0802/eval_predictions.json\", 'r') as f:\n",
    "    preds = [get_nonstop_words(x[\"prediction_text\"]) for x in json.load(f)]\n",
    "    # pickle.dump(preds, open(\"/dccstor/myu/experiments/eli5_fid_kghop2_greedy_ctx3_0802/eval_pred_nonstop.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_oracle(all_answers, all_preds):\n",
    "    overlaps = []\n",
    "    for idx in range(len(all_answers)):\n",
    "        overlap = all_answers[idx] & all_preds[idx]\n",
    "        overlaps.append([len(overlap), len(overlap)/ len(all_answers[idx]), len(overlap)/len(all_preds[idx])])\n",
    "    return overlaps\n",
    "def print_overlap(overlaps):\n",
    "    print(\n",
    "    sum(x[0] for x in overlaps)/len(overlaps), \n",
    "    sum(x[1] for x in overlaps)/len(overlaps),\n",
    "    sum(x[2] for x in overlaps)/len(overlaps), \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/dccstor/myu/experiments/knowledge_trie/eli5_openie_merge/id2kg.json\") as f:\n",
    "    data = json.loads(f.readline())\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('lfqa': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88ef27eae4435836562f365b00201516abaa7c67ef051fce85d1491a271aa183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
